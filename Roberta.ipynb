{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a64d1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vierinova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained('roberta-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06d8f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a048b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/vierinova/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", 'wikitext-103-v1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8037dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(':', ',')\n",
    "    text = text.replace('--', ',')\n",
    "    text = text.replace('-', ',')\n",
    "    text = text.replace(';', '.')\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace('♫', '')\n",
    "    text = text.replace('...', '')\n",
    "    text = text.replace('@', '')\n",
    "\n",
    "    text = re.sub(r'.\\n', ' - ', text)\n",
    "    text = re.sub(r'--\\s?--', '', text)\n",
    "    \n",
    "    text = re.sub(r'\\?+', '?', text)\n",
    "    text = re.sub(r'\\!+', '!', text)\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ',', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "\n",
    "    \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b194bdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii, how are you ? i,m! good'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('HIII: how are you ???   I-m!! Good...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: {'text': clean_text(x['text'])})\n",
    "dataset = dataset.filter(lambda x: len(x['text']) > 0 and x['text'][0] != '=', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a056e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = tokenizer.encode(\".?,-!\")[1:-1]\n",
    "target_token2id = {t: tokenizer.encode(t)[-2] for t in \".?,-!\"}\n",
    "target_ids = list(target_token2id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff1cf2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 4, '?': 116, ',': 6, '-': 12, '!': 328}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "236dd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing texts\n",
    "id2target = {\n",
    "    0: 0,\n",
    "    -1: -1,\n",
    "}\n",
    "for i, ti in enumerate(target_ids):\n",
    "    id2target[ti] = i+1\n",
    "target2id = {value: key for key, value in id2target.items()}\n",
    "\n",
    "def create_target(text):\n",
    "    encoded_words, targets = [], []\n",
    "    \n",
    "    words = text.split(' ')\n",
    "\n",
    "    for word in words:\n",
    "        target = 0\n",
    "        for target_token, target_id in target_token2id.items():\n",
    "            if word.endswith(target_token):\n",
    "                target = id2target[target_id]\n",
    "        \n",
    "        encoded_word = tokenizer.encode(word, add_special_tokens=False)\n",
    "        if len(encoded_word) == 0:\n",
    "            continue\n",
    "        for w in encoded_word:\n",
    "            encoded_words.append(w)\n",
    "        for _ in range(len(encoded_word)-1):\n",
    "            targets.append(-1)\n",
    "        targets.append(target)\n",
    "        \n",
    "        assert(len(encoded_word)>0)\n",
    "\n",
    "    encoded_words = [tokenizer.cls_token_id or tokenizer.bos_token_id] +\\\n",
    "                    encoded_words +\\\n",
    "                    [tokenizer.sep_token_id or tokenizer.eos_token_id]\n",
    "    targets = [-1] + targets + [-1]\n",
    "    \n",
    "    return encoded_words, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6365fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5914cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <s>\n",
      "1 .\n",
      "2 ?\n",
      "3 ,\n",
      "4 -\n",
      "5 !\n"
     ]
    }
   ],
   "source": [
    "for k, v in target2id.items():\n",
    "    if k != -1:\n",
    "        print(k, tokenizer.decode(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2726839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-запятая 0-пробел 1-точка 2-вопрос 4-параграф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53f3acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_symb(symb):\n",
    "    if symb == -1:\n",
    "        return ''\n",
    "    if symb == 0:\n",
    "        return ' '\n",
    "    return tokenizer.decode(target2id[symb]) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0c186d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(text):\n",
    "    encoded_input, targets = create_target(text)\n",
    "    encoded_input_tens = torch.LongTensor([encoded_input])\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(encoded_input_tens)\n",
    "        \n",
    "    output = output[0]\n",
    "    output_idx = torch.argmax(output, dim=-1)\n",
    "    array = []\n",
    "    \n",
    "    for token, symb, target in zip(encoded_input[1:-1], output_idx.numpy().tolist()[1:-1], targets[1:-1]):\n",
    "        if target == -1:\n",
    "            vale = tokenizer.decode(token)\n",
    "        elif target == 0:\n",
    "            vale = tokenizer.decode(token) + decode_symb(symb)\n",
    "        else:\n",
    "            vale = tokenizer.decode(token) + tokenizer.decode(target2id[target]) + ' '\n",
    "        array.append(vale)\n",
    "    return ''.join(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de9dba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75aed105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e78944c1fb4f28972ffad831c60acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_texts, targets = [], []\n",
    "for text in tqdm(train_text[:500_000]):\n",
    "    enc, tag = create_target(text)\n",
    "    encoded_texts.append(enc)\n",
    "    targets.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d801325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(texts, targets):\n",
    "    new_texts = []\n",
    "    new_targets = []\n",
    "    \n",
    "    for t1, t2, y1, y2 in zip(texts, texts[1:], targets, targets[1:]):\n",
    "        new_t = t1[:-1] + t2[1:]\n",
    "        new_y = y1[:-1] + y2[1:]\n",
    "        new_texts.append(new_t)\n",
    "        new_targets.append(new_y)\n",
    "    return new_texts, new_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c4cd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_targets, test_texts, test_targets = encoded_texts[:-3000], targets[:-3000], \\\n",
    "                                                        encoded_texts[-3000:], targets[-3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c201f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_targets = merge(train_texts, train_targets)\n",
    "test_texts, test_targets = merge(test_texts, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae4a50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_train_words_ro.txt', 'w') as words_file, \\\n",
    "    open('processed_train_targets_ro.txt', 'w') as targets_file:\n",
    "    for words, targets in zip(train_texts, train_targets):\n",
    "        words_file.write(' '.join(map(str, words)) + '\\n')\n",
    "        targets_file.write(' '.join(map(str, targets)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8930b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_val_words_ro.txt', 'w') as words_file, \\\n",
    "    open('processed_val_targets_ro.txt', 'w') as targets_file:\n",
    "    for words, targets in zip(test_texts, test_targets):\n",
    "        words_file.write(' '.join(map(str, words)) + '\\n')\n",
    "        targets_file.write(' '.join(map(str, targets)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e42fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "#creating datasets\n",
    "class BertDataset(Dataset):\n",
    "    def __init__(self, path, path_targets, is_train=False):\n",
    "\n",
    "        self.is_train = is_train\n",
    "        self.encoded_texts = []\n",
    "        self.targets = []\n",
    "        with open(path, 'r') as f:\n",
    "            for text in f.readlines():\n",
    "                self.encoded_texts.extend(list(map(int, text.split())))\n",
    "        with open(path_targets, 'r') as ft:\n",
    "            for text in ft.readlines():\n",
    "                self.targets.extend(list(map(int, text.split())))\n",
    "        self.encoded_texts = np.array(self.encoded_texts)\n",
    "        self.targets = np.array(self.targets)\n",
    "        idxs = []\n",
    "        \n",
    "        for i, (text, target) in enumerate(zip(self.encoded_texts, self.targets)):\n",
    "            if target >= 1:\n",
    "                idxs.append(i)\n",
    "                self.targets[i - 1] = target\n",
    "\n",
    "        self.encoded_texts = np.delete(self.encoded_texts, idxs)\n",
    "        self.targets = np.delete(self.targets, idxs)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 512\n",
    "        start_idx = max(0, start_idx)\n",
    "        end_idx = start_idx + 512\n",
    "        return torch.LongTensor(self.encoded_texts[start_idx: end_idx]),\\\n",
    "               torch.LongTensor(self.targets[start_idx: end_idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)//512 - 1\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    texts, targets = zip(*batch)\n",
    "    return torch.stack(texts), torch.stack(targets)\n",
    "\n",
    "def get_datasets():\n",
    "    train_dataset = BertDataset('processed_train_words_ro.txt', 'processed_train_targets_ro.txt', is_train=True)\n",
    "    valid_dataset = BertDataset('processed_val_words_ro.txt', 'processed_val_targets_ro.txt')\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "\n",
    "def get_data_loaders(train_dataset, valid_dataset):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, num_workers=0, collate_fn=collate, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=2, collate_fn=collate)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "415e0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4054ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data_loaders(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83b7e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = nn.Sequential(\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(512, 1))\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        binary_output = torch.sigmoid(self.x(x))\n",
    "        x = self.linear(x)\n",
    "        return x, binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8993730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1902dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class BertPunctuator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = AutoModel.from_pretrained('roberta-base', return_dict=False)\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_x = self.base(x)\n",
    "        if isinstance(base_x, tuple):\n",
    "            embedding = base_x[0]\n",
    "        else:\n",
    "            embedding = base_x.last_hidden_state\n",
    "        output, binary_output = self.classifier(embedding)\n",
    "        output = F.log_softmax(output, dim=-1)\n",
    "        return output, binary_output\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if mode:\n",
    "            self.base.train()\n",
    "            self.classifier.train()\n",
    "        else:\n",
    "            self.base.eval()\n",
    "            self.classifier.eval()\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self.train(False)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6510d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "class LinearScheduler(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, max_steps=10000):\n",
    "        self.max_steps = max_steps\n",
    "        self.lr = 0\n",
    "        super().__init__(optimizer, -1)\n",
    "\n",
    "    def get_lr(self):\n",
    "        self.lr = self.base_lrs[-1] * min(1, self._step_count/self.max_steps)\n",
    "        return [base_lr * min(1, self._step_count/self.max_steps)\n",
    "                for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3239b37",
   "metadata": {},
   "source": [
    "вводим-на самом деле\n",
    "\n",
    "0-2\n",
    "\n",
    "2-0\n",
    "\n",
    "4-4\n",
    "\n",
    "\n",
    "5-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c18e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6856035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "train_dataset, valid_dataset = get_datasets()\n",
    "train_loader, valid_loader = get_data_loaders(train_dataset, valid_dataset)\n",
    "model = BertPunctuator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6441b8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4,  5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2821e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_weights(targets, output_dim, reduce_empty=True):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=range(-1, 6), y=targets)[1:] # exclude -1\n",
    "    return weights\n",
    "\n",
    "\n",
    "target_weights = torch.Tensor(get_target_weights(train_dataset.targets, 1)).clamp_max(1).to(device)\n",
    "\n",
    "criterion = nn.NLLLoss(weight=target_weights, reduction='none')\n",
    "\n",
    "optimizer_args = [\n",
    "                {'params': model.base.parameters(), 'lr': 3e-5},\n",
    "                {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "            ]\n",
    "optimizer = torch.optim.Adam(optimizer_args)\n",
    "sched = LinearScheduler(optimizer, 500)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a66328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_state_dict.pt')\n",
    "# torch.save(optimizer.state_dict(), 'optimizer_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ccb5520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.22112272679805756, lr: 3e-05:   5%| | 7114/138954 [16:33<5:07:39,  7.14iIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.1052561029791832, lr: 3e-05:  11%| | 15114/138954 [35:08<4:48:32,  7.15iIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.1377411037683487, lr: 3e-05:  17%|▏| 22990/138954 [53:24<4:28:40,  7.19iIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.1860339641571045, lr: 3e-05:  22%|▏| 31139/138954 [1:12:18<4:11:46,  7.1IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.20704467594623566, lr: 3e-05:  28%|▎| 39063/138954 [1:30:40<3:51:12,  7.IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.10888466238975525, lr: 3e-05:  34%|▎| 47257/138954 [1:49:38<3:31:36,  7.IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.06918701529502869, lr: 3e-05:  40%|▍| 55175/138954 [2:08:00<3:15:09,  7.IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.08479779213666916, lr: 3e-05:  45%|▍| 62726/138954 [2:25:34<2:56:31,  7.IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.07904786616563797, lr: 3e-05: 100%|█| 138954/138954 [5:22:33<00:00,  7.1\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    torch.save(model.state_dict(), 'model_state_dict_roberta.pt')\n",
    "    torch.save(optimizer.state_dict(), 'optimizer_state_dict_roberta.pt')\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, data in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            text, targets = data\n",
    "            preds, binary_preds = model(text.to(device))\n",
    "\n",
    "            # Mask some \"empty\" targets\n",
    "            mask = ((targets == 0) & (np.random.rand(*targets.shape) < .1)) | (targets > 0)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            # Do not predict output after tokens which are not the end of a word\n",
    "            not_a_word_mask = (targets == -1).to(device)\n",
    "            word_mask = ~not_a_word_mask\n",
    "            targets[not_a_word_mask] = 0\n",
    "\n",
    "            losses = criterion(preds.reshape(-1, 6), targets.to(device).reshape(-1))\n",
    "            losses = losses.reshape(text.size(0), text.size(1))\n",
    "            mask = word_mask * mask\n",
    "            \n",
    "            loss = torch.sum(losses * mask) / torch.sum(mask)\n",
    "            loss.backward()\n",
    "            \n",
    "            pbar.set_description(f\"loss: {loss.item()}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.5)\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "\n",
    "        # Save model every epoch\n",
    "        torch.save(model.state_dict(), 'model_state_dict_roberta.pt')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer_state_dict_roberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b080765f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52a79ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                f1_score, roc_auc_score, precision_score, recall_score)\n",
    "\n",
    "def get_classification_report(target, preds):\n",
    "    report = classification_report(target, preds, output_dict=True)\n",
    "    report_print = classification_report(target, preds, digits=3)\n",
    "    return report, report_print\n",
    "\n",
    "\n",
    "def get_eval_metrics(targets, preds):\n",
    "    metrics = {}\n",
    "\n",
    "    preds = np.exp(preds)\n",
    "    preds = preds.reshape(-1, 6)\n",
    "    targets = targets.reshape(-1)\n",
    "    pred_index = preds.argmax(-1)\n",
    "\n",
    "    cls_report, cls_report_print = get_classification_report(targets, pred_index)\n",
    "    print(cls_report_print)\n",
    "    metrics['cls_report'] = cls_report\n",
    "\n",
    "\n",
    "    macro_precision = precision_score(targets, pred_index, average='macro')\n",
    "    metrics['precision'] = macro_precision\n",
    "\n",
    "    macro_recall = recall_score(targets, pred_index, average='macro')\n",
    "    metrics['recall'] = macro_recall\n",
    "\n",
    "    macro_f1_score = f1_score(targets, pred_index, average='macro')\n",
    "    metrics['f_score'] = macro_f1_score\n",
    "\n",
    "    auc_score = roc_auc_score(targets, preds, average='macro', multi_class='ovo')\n",
    "    metrics['auc'] = auc_score\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9cfcd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 781/781 [00:24<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.998     0.908     0.951    504793\n",
      "           1      0.779     0.948     0.855     26685\n",
      "           2      0.424     0.600     0.497        70\n",
      "           3      0.479     0.953     0.638     40426\n",
      "           4      0.896     0.893     0.894      1154\n",
      "           5      0.514     0.436     0.472       204\n",
      "\n",
      "    accuracy                          0.913    573332\n",
      "   macro avg      0.682     0.790     0.718    573332\n",
      "weighted avg      0.951     0.913     0.924    573332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valid loop\n",
    "\n",
    "model.eval()\n",
    "valid_loss = 0\n",
    "all_valid_preds = []\n",
    "all_valid_targets = []\n",
    "for data in tqdm(valid_loader):\n",
    "\n",
    "    text, targets = data\n",
    "    with torch.no_grad():\n",
    "        preds, _ = model(text.to(device))\n",
    "\n",
    "    word_mask = targets != -1\n",
    "    preds = preds[word_mask]\n",
    "    targets = targets[word_mask]\n",
    "\n",
    "    loss = criterion(preds.view(-1, 6), targets.to(device).view(-1))\n",
    "    valid_loss += loss.mean().item()\n",
    "    all_valid_preds.append(preds.detach().cpu().numpy())\n",
    "    all_valid_targets.append(targets)\n",
    "\n",
    "\n",
    "valid_loss /= len(valid_loader)\n",
    "all_valid_preds = np.concatenate(all_valid_preds)\n",
    "all_valid_targets = np.concatenate(all_valid_targets)\n",
    "\n",
    "metrics = get_eval_metrics(all_valid_targets, all_valid_preds)\n",
    "metrics[\"loss\"] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229796e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "N=512\n",
    "class BertDataset(Dataset):\n",
    "    def __init__(self, path, path_targets, is_train=False, pred_len=N):\n",
    "\n",
    "        self.is_train = is_train\n",
    "        self.encoded_texts = [0] * N\n",
    "        self.targets = [-1] * N\n",
    "        self.pred_len = pred_len\n",
    "        with open(path, 'r') as f:\n",
    "            for text in f.readlines():\n",
    "                self.encoded_texts.extend(list(map(int, text.split())))\n",
    "        with open(path_targets, 'r') as ft:\n",
    "            for text in ft.readlines():\n",
    "                self.targets.extend(list(map(int, text.split())))\n",
    "        self.encoded_texts.extend([0] * N)\n",
    "        self.targets.extend([-1] * N)\n",
    "        idxs = []\n",
    "        \n",
    "        for i, (text, target) in enumerate(zip(self.encoded_texts, self.targets)):\n",
    "            if target >= 1:\n",
    "                idxs.append(i)\n",
    "                self.targets[i - 1] = target\n",
    "\n",
    "        self.encoded_texts = np.delete(self.encoded_texts, idxs)\n",
    "        self.targets = np.delete(self.targets, idxs)\n",
    "\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.pred_len\n",
    "        start_idx = max(0, start_idx)\n",
    "        end_idx = start_idx + N\n",
    "        return torch.LongTensor(self.encoded_texts[start_idx: end_idx]),\\\n",
    "               torch.LongTensor(self.targets[start_idx: end_idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.encoded_texts) - 512)//self.pred_len - 1\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    texts, targets = zip(*batch)\n",
    "    return torch.stack(texts), torch.stack(targets)\n",
    "\n",
    "def get_datasets(pred_len):\n",
    "    train_dataset = BertDataset('processed_train_words_ro.txt', 'processed_train_targets_ro.txt', is_train=True)\n",
    "    valid_dataset = BertDataset('processed_val_words_ro.txt', 'processed_val_targets_ro.txt', pred_len=pred_len)\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "\n",
    "def get_data_loaders(train_dataset, valid_dataset):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, num_workers=0, collate_fn=collate, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=4, collate_fn=collate)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba889e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from itertools import product\n",
    "\n",
    "def collate(batch):\n",
    "    texts, targets = zip(*batch)\n",
    "    try:\n",
    "        texts, targets = torch.stack(texts), torch.stack(targets)\n",
    "    except Exception:\n",
    "        return texts[0][None, ...], targets[0][None, ...]\n",
    "    return texts, targets\n",
    "\n",
    "def combine(pred_num, preds):\n",
    "\n",
    "    ps = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        start_idx = max(0, i-512//pred_num+1)\n",
    "        end_idx = min(preds.shape[0], i+1)\n",
    "\n",
    "        p = []\n",
    "        for j, k in enumerate(range(start_idx, end_idx)):\n",
    "            j = end_idx - start_idx - j - 1\n",
    "            p.append(preds[k][j*pred_num:(j+1)*pred_num])\n",
    "        p = np.stack(p)\n",
    "        if p.shape[0] > 2:\n",
    "            p = p[1:-1, :, :]\n",
    "            \n",
    "        ps.append(np.log(np.exp(p).mean(0)))\n",
    "    ps = np.concatenate(ps)\n",
    "    return ps\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff175c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = nn.Sequential(\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(512, 1))\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        binary_output = torch.sigmoid(self.x(x))\n",
    "        x = self.linear(x)\n",
    "        return x, binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aabb3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertPunctuator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        config = AutoConfig.from_pretrained('roberta-base')\n",
    "        self.base = AutoModel.from_pretrained('roberta-base')\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.base(x).last_hidden_state\n",
    "\n",
    "        output, binary_output = self.classifier(embedding)\n",
    "        output = F.log_softmax(output, dim=-1)\n",
    "        return output, binary_output\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if mode:\n",
    "            self.base.train()\n",
    "            self.classifier.train()\n",
    "        else:\n",
    "            self.base.eval()\n",
    "            self.classifier.eval()\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self.train(False)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e09b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd6f30d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertPunctuator()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('model_state_dict_roberta.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae8c5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                f1_score, roc_auc_score, precision_score, recall_score)\n",
    "\n",
    "def get_classification_report(target, preds):\n",
    "    report = classification_report(target, preds, output_dict=True)\n",
    "    report_print = classification_report(target, preds)\n",
    "    return report, report_print\n",
    "\n",
    "\n",
    "def get_eval_metrics(targets, preds, make_paragraphs = True, short_sentenses = False):\n",
    "    # TODO: get the desired metric list from config-frozen.yaml\n",
    "    \"\"\"\n",
    "    Calculates metrics on validation data\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    if make_paragraphs == False:\n",
    "        preds = preds[:, :-1]\n",
    "    preds = np.exp(preds)\n",
    "    preds = preds.reshape(-1, 6)\n",
    "    targets = targets.reshape(-1)\n",
    "    pred_index = preds.argmax(-1)\n",
    "    \n",
    "    if short_sentenses == True:\n",
    "        new_preds = []\n",
    "        for i in range(len(pred_index)):\n",
    "            cur_pred_idx = pred_index[i]\n",
    "            if cur_pred_idx == 3:\n",
    "                next_index = preds[i][preds[i].argsort()[:-2]]\n",
    "                if preds[i, cur_pred_idx] - preds[i, next_index] < 0.3:\n",
    "                    cur_pred_idx = next_index\n",
    "            new_preds.append(cur_pred_idx)\n",
    "        new_preds = np.array(new_preds)\n",
    "        pred_index = new_preds\n",
    "\n",
    "    cls_report, cls_report_print = get_classification_report(targets, pred_index)\n",
    "    print(cls_report_print)\n",
    "    metrics['cls_report'] = cls_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffd6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi_preds(N_PREDICTIONS_FOR_TOKEN, model):\n",
    "    PREDICTION_NUM = N_PREDICTIONS_FOR_TOKEN\n",
    "    WINDOW_SHIFT = 512 // PREDICTION_NUM\n",
    "    train, test_dataset = get_datasets(pred_len=WINDOW_SHIFT)\n",
    "    train_loader, test_loader = get_data_loaders(train, test_dataset)\n",
    "    model.eval()\n",
    "    all_test_preds = []\n",
    "\n",
    "    for data in tqdm(test_loader):\n",
    "        text, targets = data\n",
    "        with torch.no_grad():\n",
    "            preds, _ = model(text.to(device))\n",
    "\n",
    "        all_test_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    all_valid_target = test_dataset.targets\n",
    "    all_valid_preds = np.concatenate(all_test_preds)\n",
    "    ps = combine(512 // PREDICTION_NUM, all_valid_preds)\n",
    "    _targets = np.array(all_valid_target[:ps.shape[0]])\n",
    "\n",
    "    ps = ps[_targets != -1]\n",
    "    _targets = _targets[_targets != -1]\n",
    "\n",
    "    return(get_eval_metrics(_targets, ps), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365943a",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "1 .\n",
    "    \n",
    "2 ?\n",
    "    \n",
    "3 ,\n",
    "    \n",
    "4 -\n",
    "    \n",
    "5 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c1141ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 391/391 [00:23<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    504793\n",
      "           1       0.78      0.95      0.86     26685\n",
      "           2       0.42      0.60      0.50        70\n",
      "           3       0.48      0.95      0.64     40426\n",
      "           4       0.90      0.89      0.89      1154\n",
      "           5       0.51      0.44      0.47       204\n",
      "\n",
      "    accuracy                           0.91    573332\n",
      "   macro avg       0.68      0.79      0.72    573332\n",
      "weighted avg       0.95      0.91      0.92    573332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps1 = make_multi_preds(1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9be4e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [00:47<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    504976\n",
      "           1       0.79      0.95      0.86     26691\n",
      "           2       0.47      0.63      0.54        70\n",
      "           3       0.48      0.96      0.64     40439\n",
      "           4       0.90      0.89      0.89      1154\n",
      "           5       0.50      0.45      0.47       204\n",
      "\n",
      "    accuracy                           0.91    573534\n",
      "   macro avg       0.69      0.80      0.73    573534\n",
      "weighted avg       0.95      0.91      0.93    573534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps2 = make_multi_preds(2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bfa47f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1564/1564 [01:34<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    505176\n",
      "           1       0.79      0.95      0.86     26697\n",
      "           2       0.49      0.66      0.56        70\n",
      "           3       0.49      0.96      0.64     40447\n",
      "           4       0.90      0.88      0.89      1154\n",
      "           5       0.50      0.44      0.47       204\n",
      "\n",
      "    accuracy                           0.92    573748\n",
      "   macro avg       0.69      0.80      0.73    573748\n",
      "weighted avg       0.95      0.92      0.93    573748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps4 = make_multi_preds(4, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d7275be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3129/3129 [03:10<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    505221\n",
      "           1       0.79      0.95      0.86     26698\n",
      "           2       0.49      0.66      0.56        70\n",
      "           3       0.49      0.96      0.65     40452\n",
      "           4       0.90      0.88      0.89      1154\n",
      "           5       0.53      0.46      0.49       204\n",
      "\n",
      "    accuracy                           0.92    573799\n",
      "   macro avg       0.70      0.80      0.74    573799\n",
      "weighted avg       0.95      0.92      0.93    573799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps8 = make_multi_preds(8, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31f0e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6257/6257 [06:20<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    505264\n",
      "           1       0.80      0.95      0.87     26701\n",
      "           2       0.51      0.66      0.57        70\n",
      "           3       0.49      0.96      0.65     40453\n",
      "           4       0.90      0.89      0.90      1154\n",
      "           5       0.53      0.45      0.49       204\n",
      "\n",
      "    accuracy                           0.92    573846\n",
      "   macro avg       0.70      0.80      0.74    573846\n",
      "weighted avg       0.95      0.92      0.93    573846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps16 = make_multi_preds(16, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f79446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 12515/12515 [12:41<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    505275\n",
      "           1       0.80      0.95      0.87     26701\n",
      "           2       0.50      0.66      0.57        70\n",
      "           3       0.49      0.96      0.65     40453\n",
      "           4       0.90      0.89      0.90      1154\n",
      "           5       0.52      0.45      0.48       204\n",
      "\n",
      "    accuracy                           0.92    573857\n",
      "   macro avg       0.70      0.80      0.74    573857\n",
      "weighted avg       0.95      0.92      0.93    573857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps32 = make_multi_preds(32, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy 0.92\n",
    "macro avg 0.74\n",
    "weighted avg 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ca2dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 25029/25029 [25:22<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95    505282\n",
      "           1       0.80      0.95      0.87     26702\n",
      "           2       0.51      0.66      0.57        70\n",
      "           3       0.49      0.96      0.65     40453\n",
      "           4       0.91      0.89      0.90      1154\n",
      "           5       0.53      0.46      0.49       204\n",
      "\n",
      "    accuracy                           0.92    573865\n",
      "   macro avg       0.70      0.80      0.74    573865\n",
      "weighted avg       0.95      0.92      0.93    573865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rev, ps64 = make_multi_preds(64, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d47dd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='a book display with works on critical race theory critical race theory (crt) is a cross disciplinary intellectual and social movement of civil rights scholars and activists who seek to examine the intersection of race society and law in the united states and to challenge mainstream american liberal approaches to racial justice the word critical in its name is an academic term that refers to critical thinking critical theory and scholarly criticism rather than criticizing or blaming people crt is also used in sociology to explain social political and legal structures and power distribution through the lens of race for example the crt conceptual framework is one way to study racial bias in laws and institutions such as the how and why of incarceration rates and how sentencing differs among racial groups in the united states it first arose in the 1970s like other critical schools of thought such as critical legal studies which examines how legal rules protect the status quo a key crt concept is intersectionality the way in which different forms of inequality and identity are affected by interconnections of race class gender and disability scholars of crt view race as a social construct with no biological basis one tenet of crt is that racism and disparate racial outcomes are the result of complex changing and often subtle social and institutional dynamics rather than explicit and intentional prejudices of individuals crt scholars argue that the social and legal construction of race advances the interests of white people at the expense of people of color and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where formally color,blind laws continue to have racially discriminatory outcomes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a965e0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book, display, with works on critical race theory. critical race theory (crt) is a cross, disciplinary, intellectual, and social movement of civil rights scholars, and activists, who seek to examine the intersection of race, society, and law in the united states, and to challenge mainstream, american, liberal approaches to racial justice. the word critical, in its name, is an academic term that refers to critical thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology to explain social, political, and legal structures, and power distribution, through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how, and why of incarceration rates, and how sentencing differs among racial groups. in the united states. it first arose in the 1970s. like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status, quo. a key crt concept is intersectionality, the way in which different forms of inequality, and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct, with no biological basis. one tenet of crt is that racism and disparate racial outcomes are the result of complex, changing, and often, subtle, social, and institutional dynamics, rather than explicit, and intentional, prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people, at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially, unjust social order, where, formally, color,blind laws continue to have racially discriminatory outcomes. '"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08efe831",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text=clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "908e03d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book display with works on critical race theory critical race theory (crt) is a cross,disciplinary intellectual and social movement of civil,rights scholars and activists who seek to examine the intersection of race, society, and law in the united states and to challenge mainstream american liberal approaches to racial justice. the word critical in its name is an academic term that refers to critical thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology to explain social, political, and legal structures and power distribution through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how and why of incarceration rates and how sentencing differs among racial groups in the united states. it first arose in the 1970s, like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status quo. a key crt concept is intersectionality—the way in which different forms of inequality and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct with no biological basis. one tenet of crt is that racism and disparate racial outcomes are the result of complex, changing, and often subtle social and institutional dynamics, rather than explicit and intentional prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where formally color,blind laws continue to have racially discriminatory outcomes.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "7d3e1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_symb(symb):\n",
    "    if symb == -1:\n",
    "        return ''\n",
    "    if symb == 0:\n",
    "        return ' '\n",
    "    decoded = tokenizer.decode(target2id[symb])\n",
    "    return decoded + ' '\n",
    "\n",
    "def predict_model(text, short_sentenses=False):\n",
    "    encoded_input, targets = create_target(text)\n",
    "    encoded_input_tens = torch.LongTensor([encoded_input]).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(encoded_input_tens)[0]\n",
    "    output = output[0]\n",
    "    output = torch.softmax(output, dim=-1)\n",
    "    output_idx = torch.argmax(output, dim=-1)\n",
    "    if short_sentenses:\n",
    "        new_preds = []\n",
    "        for i in range(len(output_idx)):\n",
    "            cur_pred_idx = output_idx[i]\n",
    "            next_index = output[i].argsort()[-2]\n",
    "            if output[i, 1] > 0.004:\n",
    "                cur_pred_idx = torch.LongTensor([1])[0]\n",
    "            \n",
    "            new_preds.append(cur_pred_idx.detach().cpu().numpy().tolist())\n",
    "        new_preds = np.array(new_preds)\n",
    "        output_idx = torch.from_numpy(new_preds)\n",
    "        pred_index = new_preds\n",
    "\n",
    "\n",
    "    array = []\n",
    "    \n",
    "    for token, symb, target in zip(encoded_input[1:-1], output_idx.cpu().numpy().tolist()[1:-1], targets[1:-1]):\n",
    "        if target == -1:\n",
    "            vale = tokenizer.decode(token)\n",
    "        elif target == 0:\n",
    "            vale = tokenizer.decode(token) + decode_symb(symb)\n",
    "        else:\n",
    "            token_dec = tokenizer.decode(token)\n",
    "            target_dec = tokenizer.decode(target2id[target])\n",
    "            vale = token_dec\n",
    "            if token_dec.strip()[-1] != target_dec.strip()[-1]:\n",
    "                vale = vale + target_dec\n",
    "            vale = vale + ' '\n",
    "        array.append(vale)\n",
    "    return ''.join(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "49a3033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If i could save time in the bottle, first thing that i would to do, is, to save every day, till eternaty passes away. '"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model('If i could save time in the bottle first thing that i would to do is to save '\n",
    "              'every day till eternaty passes away')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "844582ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If i could save time. in the bottle. first thing that i would to do, is. to save. every day. till eternaty. passes away. '"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model('If i could save time in the bottle first thing that i would to do is to save '\n",
    "              'every day till eternaty passes away', short_sentenses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "28840a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "809b6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='I hate him because of his stubbornness How do I handle this'\n",
    "prepared_text=clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "922efc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hate him because of his stubbornness how do i handle this'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "73d61672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hate him, because of his stubbornness. how do i handle this? '"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25b2db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = model(torch.LongTensor([encoded_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02672f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0395,  0.0281, -0.0182,  ..., -0.2276, -0.0229,  0.0374],\n",
       "         [-0.2320, -0.5142, -0.1307,  ..., -0.2004,  0.0440,  0.3378],\n",
       "         [-0.0358, -0.0342,  0.1395,  ..., -0.4272,  0.0173,  0.3511],\n",
       "         ...,\n",
       "         [ 0.1921,  0.1700, -0.0792,  ..., -0.0158,  0.0190,  0.2110],\n",
       "         [-0.0427,  0.0319, -0.0388,  ..., -0.2669, -0.0295,  0.0111],\n",
       "         [-0.0277, -0.0830,  0.1402,  ..., -0.1500, -0.0749,  0.1609]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-5.5298e-03, -2.4003e-01, -1.8299e-01, -1.2790e-01,  1.5247e-01,\n",
       "          2.2248e-01,  2.3798e-01, -7.0888e-02, -9.6683e-02, -1.8161e-01,\n",
       "          2.7784e-01,  5.1404e-02, -1.4909e-01,  5.5379e-02, -1.3808e-01,\n",
       "          5.0662e-01,  2.9180e-01, -4.7211e-01,  6.5626e-02,  8.2297e-03,\n",
       "         -2.2727e-01,  9.9285e-02,  4.8312e-01,  2.9684e-01,  1.3221e-01,\n",
       "          1.0195e-01, -1.8300e-01, -1.1211e-02,  1.4573e-01,  2.1948e-01,\n",
       "          3.0507e-01,  2.0021e-02,  1.5335e-01,  2.6514e-01, -2.6367e-01,\n",
       "          4.8291e-02, -2.8954e-01,  1.6543e-02,  2.6936e-01, -1.8964e-01,\n",
       "         -6.3405e-02,  2.4369e-01,  1.5545e-01, -1.3059e-01, -1.0851e-01,\n",
       "          4.1905e-01,  2.1240e-01,  7.2053e-02, -1.6079e-01, -1.0139e-01,\n",
       "         -3.6294e-01,  3.6634e-01,  3.1233e-01,  2.2165e-01, -4.9137e-02,\n",
       "          2.5863e-02, -1.1535e-01,  2.7113e-01, -4.1723e-02, -3.6980e-02,\n",
       "         -1.4679e-01, -1.8020e-01,  3.9560e-02, -5.5966e-02, -3.2337e-02,\n",
       "         -1.1470e-01,  1.2319e-01, -1.9346e-01, -1.4908e-01,  4.6010e-02,\n",
       "         -7.4129e-02,  9.2611e-02,  1.8153e-01, -2.8642e-01, -2.6817e-01,\n",
       "          8.0637e-02, -6.2222e-01, -6.1030e-02,  2.9992e-01,  4.0379e-01,\n",
       "         -8.3479e-02,  2.3583e-01, -2.4030e-02,  1.8573e-01, -2.9482e-02,\n",
       "         -2.7375e-02, -3.3953e-02, -1.1005e-01,  1.7475e-01,  3.5382e-01,\n",
       "         -2.1453e-01, -4.0225e-01,  8.7959e-02,  3.8278e-02, -6.8551e-02,\n",
       "          5.6072e-02, -2.5248e-02, -5.1716e-02, -2.4879e-01, -1.7199e-01,\n",
       "          1.1320e-01, -2.5266e-01, -1.0941e-01,  1.9758e-01,  2.1771e-02,\n",
       "         -2.3052e-01, -6.0601e-02,  2.8782e-01,  7.8614e-02, -1.0026e-01,\n",
       "         -8.9864e-02,  4.4120e-01,  2.9116e-01,  7.5823e-04,  6.0305e-02,\n",
       "          1.5694e-01,  9.6643e-02, -3.0200e-01,  4.3409e-01, -3.1324e-01,\n",
       "         -1.2535e-02, -8.4170e-02,  1.4592e-01,  1.5189e-01, -2.0419e-01,\n",
       "          2.7192e-01,  1.3472e-01,  2.5618e-01,  1.7185e-01,  5.1871e-02,\n",
       "         -3.4127e-02,  1.0269e-01, -1.4218e-01,  1.7424e-01,  1.6775e-01,\n",
       "          1.2018e-01,  1.8874e-02, -3.7214e-01, -2.5743e-01,  2.4042e-01,\n",
       "          3.6812e-01,  1.0628e-01, -6.7140e-04,  2.2729e-01,  1.2131e-01,\n",
       "          2.6565e-01,  1.7540e-01, -3.8754e-01,  6.7076e-02,  3.2692e-01,\n",
       "          7.9352e-02,  1.3381e-01, -1.1501e-01, -2.8844e-01, -2.4911e-01,\n",
       "         -3.0630e-02,  4.6246e-04, -3.0066e-01, -7.8924e-02,  3.7242e-01,\n",
       "         -2.3381e-02, -4.1591e-02, -1.7133e-01, -1.7856e-01, -9.0655e-02,\n",
       "         -1.7954e-01,  5.5997e-02,  1.0843e-01, -4.3345e-02, -4.1053e-01,\n",
       "         -1.3977e-01, -5.5419e-01, -1.4247e-01,  2.4867e-01, -3.1171e-01,\n",
       "          2.9861e-01, -2.9030e-01,  7.4514e-02,  3.9670e-01,  1.9606e-02,\n",
       "          2.3093e-02, -2.0177e-01, -1.4632e-02,  6.3708e-02,  2.9080e-01,\n",
       "          2.3520e-01, -3.9363e-01,  7.8761e-02,  2.0108e-01,  2.6071e-01,\n",
       "          1.5247e-01,  1.5034e-03, -1.6338e-01,  9.7942e-02, -2.2819e-01,\n",
       "          1.7610e-01, -2.2880e-01,  1.2800e-01, -2.4686e-01, -2.1760e-01,\n",
       "          3.1776e-01, -3.9501e-01, -1.0281e-01,  5.1245e-02,  2.0987e-01,\n",
       "          5.0276e-02, -7.2432e-02, -1.0155e-01,  7.6069e-02,  2.0273e-01,\n",
       "          1.3765e-01, -4.1862e-01,  2.5776e-01, -3.0138e-02, -8.4258e-02,\n",
       "         -5.2625e-02,  1.8545e-01,  2.3867e-01,  1.2956e-01, -3.9167e-01,\n",
       "         -1.4731e-01,  1.2994e-01,  2.5172e-01, -2.7597e-01,  1.5455e-01,\n",
       "         -2.0347e-01, -4.1317e-01, -1.5805e-01,  1.9266e-01,  2.4567e-01,\n",
       "          1.3081e-01, -2.4089e-01,  1.4175e-01, -1.0113e-01, -4.0701e-01,\n",
       "         -3.1652e-01, -5.9605e-02,  2.6446e-01,  1.3589e-01,  1.3608e-01,\n",
       "          2.7011e-01,  3.7630e-02,  1.0632e-01,  1.4446e-01,  1.6463e-01,\n",
       "         -1.6000e-01,  1.5281e-01, -3.7002e-01, -6.5700e-02, -3.1551e-01,\n",
       "         -2.2832e-01, -2.2742e-01,  4.2163e-01, -2.6381e-01,  1.9364e-01,\n",
       "          4.2134e-01, -3.1316e-01, -9.2800e-02,  1.6141e-01,  1.2270e-01,\n",
       "          1.2791e-01, -1.6121e-01,  2.1331e-01,  1.0519e-01, -3.0422e-02,\n",
       "          2.4600e-01,  6.4044e-03,  2.3628e-01,  1.7817e-01,  5.1597e-02,\n",
       "          1.2728e-01,  1.4337e-01, -1.6764e-01,  4.9535e-02, -4.5713e-02,\n",
       "         -4.3397e-02, -2.9495e-01, -1.1889e-01,  2.1382e-01, -8.9087e-02,\n",
       "          5.2352e-02, -1.7226e-01, -3.5465e-02, -1.1861e-02,  4.2481e-01,\n",
       "         -3.6122e-01,  2.3402e-01,  4.0346e-02,  1.6925e-01, -2.6491e-01,\n",
       "         -1.7575e-01,  9.4434e-02,  2.0706e-01, -4.3295e-01,  2.9698e-03,\n",
       "          1.4302e-01,  1.4166e-01,  2.0427e-01,  2.5915e-01,  1.8697e-02,\n",
       "         -1.4001e-01,  5.1337e-01, -1.2269e-01, -1.6052e-01,  2.6836e-01,\n",
       "         -2.6405e-01, -2.3935e-01,  2.1054e-01,  2.1781e-02,  3.3675e-01,\n",
       "          1.2716e-01,  7.7809e-02,  5.9580e-02, -5.9446e-01,  2.7837e-02,\n",
       "         -4.6306e-01,  7.3120e-03,  3.6604e-02, -1.0746e-01, -1.6230e-01,\n",
       "          1.2371e-01,  2.9934e-01, -2.1880e-01, -4.6500e-02,  2.1701e-01,\n",
       "          7.8925e-02, -1.3051e-01,  4.6331e-01, -1.2183e-02,  2.1509e-01,\n",
       "         -7.3139e-02,  2.0029e-01, -1.8901e-01,  2.9039e-01, -3.1373e-01,\n",
       "         -8.5442e-02,  1.6922e-02,  2.5922e-02,  8.9829e-02, -7.4323e-02,\n",
       "         -3.0956e-01,  2.6432e-01, -4.6072e-02, -7.6515e-02, -3.9204e-02,\n",
       "          1.2963e-01,  9.0518e-03,  5.7988e-02,  5.7640e-02,  3.3977e-01,\n",
       "          2.6958e-01, -4.3031e-02, -3.8823e-01, -8.2126e-03, -1.1759e-01,\n",
       "          7.3812e-02, -5.5447e-03,  4.3355e-02,  4.8364e-01, -1.0200e-01,\n",
       "         -4.2205e-02, -7.1849e-02,  2.3112e-01,  2.3755e-01,  1.1766e-01,\n",
       "          1.7885e-01,  3.4063e-02,  1.6581e-01, -4.0079e-02, -1.1498e-02,\n",
       "         -1.1163e-01, -2.2163e-01, -2.9932e-01,  2.4614e-01, -2.3581e-01,\n",
       "         -1.7585e-01,  1.8277e-01,  2.3786e-01, -1.0809e-01,  1.6281e-01,\n",
       "          3.1625e-01,  1.7054e-01, -1.7208e-01,  2.4414e-01, -7.7034e-02,\n",
       "          9.0945e-02,  2.6482e-01, -1.5453e-03,  1.4075e-01,  5.0390e-01,\n",
       "          2.5754e-01, -3.5250e-01, -1.0199e-02, -2.3841e-01, -1.2850e-02,\n",
       "          2.4013e-01, -1.6297e-01,  1.5340e-01,  4.1853e-01,  2.8462e-01,\n",
       "          4.4832e-01, -6.5939e-03, -1.2257e-01,  1.7373e-01,  1.5204e-01,\n",
       "          7.3209e-02, -1.7560e-01, -2.1348e-01,  2.3025e-01,  4.5499e-02,\n",
       "         -1.3362e-01,  4.8922e-02, -1.8524e-01,  3.7108e-02, -1.3352e-01,\n",
       "         -3.4604e-01,  4.9847e-02,  1.9375e-01, -4.7599e-01,  1.4175e-01,\n",
       "         -2.9059e-01,  7.0521e-02, -2.3761e-01,  2.1715e-01, -2.8437e-01,\n",
       "         -7.9715e-02,  3.7052e-01, -8.9619e-02,  1.1847e-02, -2.2862e-01,\n",
       "         -8.6579e-02,  4.9578e-02,  2.5107e-02, -3.7136e-02,  4.3646e-02,\n",
       "          3.4920e-01, -1.1729e-01,  1.7029e-02,  5.7005e-02,  2.6451e-01,\n",
       "         -7.2178e-02,  2.0079e-01,  4.0091e-02, -1.1807e-01, -3.9296e-01,\n",
       "          1.6718e-01, -1.9138e-01, -4.4269e-01, -3.4781e-01,  3.8735e-01,\n",
       "         -1.3619e-01, -2.6541e-01, -1.7199e-01, -2.9501e-01,  8.1621e-02,\n",
       "          2.3937e-01,  4.6191e-01, -4.0751e-01,  4.2029e-03,  4.6399e-01,\n",
       "         -8.8451e-02, -1.8365e-01,  2.5505e-01,  2.3563e-01, -3.0819e-01,\n",
       "          3.1473e-01,  2.7138e-01, -4.8597e-02,  5.1051e-02,  5.2386e-01,\n",
       "          1.2966e-01,  1.6717e-01, -1.9748e-01,  4.8839e-01, -2.2094e-01,\n",
       "          2.7184e-01, -2.4695e-01, -1.5440e-01, -1.9844e-01, -5.6075e-02,\n",
       "          3.2925e-01,  1.9637e-01, -3.9155e-01, -1.4688e-01,  2.4425e-02,\n",
       "          3.1250e-01, -3.1276e-01, -2.2312e-02, -4.5959e-03, -3.0686e-01,\n",
       "          1.4807e-01,  1.3935e-01,  2.6347e-01, -4.2336e-01, -7.4419e-02,\n",
       "          4.0443e-01, -3.1432e-01,  1.2058e-01,  3.0881e-01,  8.6667e-02,\n",
       "          4.0409e-01, -4.5393e-03, -3.2635e-03,  8.4003e-02, -2.5222e-01,\n",
       "         -2.2090e-03,  1.2618e-01,  5.3961e-01,  1.2664e-01, -3.7534e-01,\n",
       "          5.9115e-02,  2.1222e-01, -1.1924e-01,  3.2343e-01, -4.3500e-02,\n",
       "         -1.0865e-01,  3.0179e-01,  4.9262e-03,  9.0896e-02, -8.7422e-02,\n",
       "         -1.7171e-01, -3.2112e-01,  3.4956e-01, -2.4239e-01, -1.0425e-01,\n",
       "         -1.0813e-01, -1.4371e-01, -1.3217e-01,  5.7135e-02, -3.9077e-01,\n",
       "          3.4216e-01,  1.4027e-01, -1.9950e-01, -6.5869e-02, -6.0254e-02,\n",
       "         -1.2168e-01, -2.3034e-01, -2.9877e-01,  3.7854e-01, -1.1965e-01,\n",
       "         -4.4625e-01,  2.4359e-01,  2.1361e-02,  3.6079e-01, -2.7452e-02,\n",
       "          1.5611e-01, -4.7145e-02,  1.5451e-01,  1.1667e-01, -9.8319e-02,\n",
       "          2.6572e-01,  1.4642e-01, -5.7582e-01, -1.2766e-01, -2.0706e-01,\n",
       "          9.8240e-02,  2.0206e-01, -3.4022e-01, -4.8210e-02,  7.6440e-03,\n",
       "          1.1877e-01,  9.2504e-02, -3.4754e-02, -5.9199e-02,  4.1090e-01,\n",
       "          2.0455e-01,  2.4673e-01,  1.0249e-01,  2.0072e-01,  2.0769e-02,\n",
       "         -2.6568e-01, -1.0762e-02,  7.5836e-02, -1.8319e-01,  4.5049e-01,\n",
       "         -4.6266e-02, -3.8757e-01, -9.1443e-02,  3.9883e-01,  8.2839e-02,\n",
       "         -1.1573e-02, -4.8857e-02,  2.1119e-01,  1.4923e-01, -9.1269e-02,\n",
       "          1.9696e-01, -3.3994e-02, -1.3440e-01, -8.7294e-02,  1.4848e-01,\n",
       "         -2.4532e-01,  8.1218e-02, -1.3521e-01,  6.8564e-04, -2.6202e-01,\n",
       "          6.4197e-02, -2.1492e-01,  2.2356e-01, -3.3630e-01,  1.1030e-01,\n",
       "          1.2148e-01,  3.3204e-01, -3.2241e-01, -1.4669e-01, -5.3283e-02,\n",
       "          2.1047e-01,  2.4013e-01,  3.5737e-01, -3.3532e-02, -1.6408e-02,\n",
       "         -1.7314e-01, -2.4664e-01,  8.4884e-02, -2.0524e-01,  1.6552e-01,\n",
       "          5.9029e-02,  2.2317e-01, -3.2741e-01, -1.7568e-01,  1.7977e-01,\n",
       "         -4.6284e-02, -1.5511e-01,  4.4426e-01,  2.8996e-01,  2.2046e-01,\n",
       "          5.5666e-02,  2.3287e-01,  5.8796e-02, -2.3435e-01, -9.5062e-02,\n",
       "         -2.2918e-01,  1.3015e-01, -1.1730e-01, -5.6302e-02, -2.0526e-02,\n",
       "         -1.8011e-01, -1.8687e-01, -1.7002e-01,  1.1800e-01,  7.7215e-02,\n",
       "         -9.9611e-03, -5.8639e-02, -2.6695e-02, -2.7219e-01,  2.9318e-01,\n",
       "          1.5502e-02,  4.0616e-02, -1.0573e-01,  8.0459e-02, -9.7773e-02,\n",
       "          1.8560e-01,  2.5666e-01,  3.9380e-02, -1.8307e-01, -5.8169e-02,\n",
       "         -3.3148e-01, -3.4895e-01,  7.8680e-02,  1.4836e-01,  1.1311e-01,\n",
       "         -4.1762e-02, -2.0860e-01,  2.4736e-02, -1.0404e-01,  1.6031e-01,\n",
       "          9.3129e-03, -1.2623e-01, -1.0022e-01, -5.5367e-02, -1.4300e-02,\n",
       "          1.2539e-01, -1.7919e-01, -2.0852e-01, -1.4967e-01, -6.4980e-02,\n",
       "         -5.7868e-02,  3.7844e-01,  7.2715e-03,  3.1756e-01, -1.4146e-01,\n",
       "          5.1797e-03, -1.3866e-01,  1.3403e-01, -7.8688e-02,  8.7399e-02,\n",
       "          2.8252e-01, -4.2799e-01, -1.6142e-01, -2.0442e-02, -2.4489e-01,\n",
       "         -8.7682e-02, -6.7515e-02, -2.9315e-02,  2.1942e-01, -3.6753e-01,\n",
       "          2.0352e-01, -9.4669e-02,  1.7116e-01, -1.5422e-02, -2.1315e-01,\n",
       "         -1.4684e-01,  5.0664e-03,  2.5819e-01, -3.7632e-01, -2.3103e-01,\n",
       "         -2.6901e-01, -1.3993e-01, -8.8208e-02, -2.1678e-01,  4.3865e-01,\n",
       "         -1.2709e-01, -4.6802e-02,  6.6809e-02,  4.6481e-01,  2.2930e-01,\n",
       "          1.4245e-01,  1.9718e-01, -2.1053e-02,  1.1073e-02,  8.6177e-02,\n",
       "         -4.6371e-01,  2.2297e-01, -2.1009e-01, -1.4364e-01,  1.2808e-03,\n",
       "          6.4757e-02, -3.1861e-02,  1.1841e-02, -1.6588e-01, -9.5237e-02,\n",
       "          2.3157e-01, -3.7507e-01, -2.4320e-02,  2.4582e-01,  8.3910e-02,\n",
       "         -2.8352e-01,  1.0017e-01,  1.6940e-01,  3.9850e-01,  1.1112e-01,\n",
       "         -2.0726e-01,  1.9447e-01, -2.8925e-01, -5.5350e-03, -1.8693e-01,\n",
       "         -3.2208e-01,  9.2900e-02, -7.5916e-02,  9.8342e-02, -9.5411e-03,\n",
       "         -3.0830e-01,  2.5177e-01, -7.8883e-02, -3.3947e-02,  4.2959e-01,\n",
       "          3.8767e-04, -4.5627e-02,  1.8426e-01,  2.2810e-02,  7.8166e-02,\n",
       "         -1.1709e-01,  2.2168e-01,  1.4973e-01, -2.9768e-01,  1.0913e-01,\n",
       "         -1.6226e-01, -5.1764e-02, -1.1908e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model(torch.LongTensor([encoded_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96c6df41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0395,  0.0281, -0.0182,  ..., -0.2276, -0.0229,  0.0374],\n",
       "         [-0.2320, -0.5142, -0.1307,  ..., -0.2004,  0.0440,  0.3378],\n",
       "         [-0.0358, -0.0342,  0.1395,  ..., -0.4272,  0.0173,  0.3511],\n",
       "         ...,\n",
       "         [ 0.1921,  0.1700, -0.0792,  ..., -0.0158,  0.0190,  0.2110],\n",
       "         [-0.0427,  0.0319, -0.0388,  ..., -0.2669, -0.0295,  0.0111],\n",
       "         [-0.0277, -0.0830,  0.1402,  ..., -0.1500, -0.0749,  0.1609]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model(torch.LongTensor([encoded_input]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7549b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi_preds(N_PREDICTIONS_FOR_TOKEN, model):\n",
    "    PREDICTION_NUM = N_PREDICTIONS_FOR_TOKEN\n",
    "    WINDOW_SHIFT = 512 // PREDICTION_NUM\n",
    "    train, test_dataset = get_datasets(pred_len=WINDOW_SHIFT)\n",
    "    train_loader, test_loader = get_data_loaders(train, test_dataset)\n",
    "    model.eval()\n",
    "    all_test_preds = []\n",
    "\n",
    "    for data in tqdm(test_loader):\n",
    "        text, targets = data\n",
    "        with torch.no_grad():\n",
    "            preds, _ = model(text.to(device))\n",
    "\n",
    "        all_test_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    all_valid_target = test_dataset.targets\n",
    "    all_valid_preds = np.concatenate(all_test_preds)\n",
    "    ps = combine(512 // PREDICTION_NUM, all_valid_preds)\n",
    "    _targets = np.array(all_valid_target[:ps.shape[0]])\n",
    "\n",
    "    ps = ps[_targets != -1]\n",
    "    _targets = _targets[_targets != -1]\n",
    "\n",
    "    return get_eval_metrics(_targets, ps, short_sentenses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "683d8db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d622672018420d80d527d692a6e077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1905862/2443909336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_multi_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1905862/4044127309.py\u001b[0m in \u001b[0;36mmake_multi_preds\u001b[0;34m(N_PREDICTIONS_FOR_TOKEN, model)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_sentenses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1905862/1273102481.py\u001b[0m in \u001b[0;36mget_eval_metrics\u001b[0;34m(targets, preds, make_paragraphs, short_sentenses)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcur_pred_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_pred_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mcur_pred_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mnew_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_pred_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "metrics = make_multi_preds(1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02627a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
