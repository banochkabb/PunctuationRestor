{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5394b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vierinova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "# config = AutoConfig.from_pretrained('microsoft/deberta-v3-large')\n",
    "# config.max_position_embeddings = 1024\n",
    "# model = AutoModel.from_pretrained('microsoft/deberta-v3-large', config=config)\n",
    "\n",
    "checkpoint = 'microsoft/deberta-v3-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bd2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b203e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(':', ',')\n",
    "    text = text.replace('--', ',')\n",
    "    text = text.replace('-', ',')\n",
    "    text = text.replace(';', '.')\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace('♫', '')\n",
    "    text = text.replace('...', '')\n",
    "    text = text.replace('@', '')\n",
    "\n",
    "    text = re.sub(r'.\\n', ' - ', text)\n",
    "    text = re.sub(r'--\\s?--', '', text)\n",
    "    \n",
    "    text = re.sub(r'\\s+\\?', '?', text)\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ',', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "\n",
    "    \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc89941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vierinova/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-992142716dc4055c.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: {'text': clean_text(x['text'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0ee5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/vierinova/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-cfefd0cd2f2d0810.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: len(x['text']) > 0 and x['text'][0] != '=', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ffb8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859532"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = dataset['text']\n",
    "len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9268a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_text[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "def001b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, -1: -1, 1: 323, 2: 1102, 3: 366, 4: 341, 5: 1084}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ff673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "68044fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text, test_target = train_dataset.encoded_texts[:15], train_dataset.targets[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "89d7c521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 32862,\n",
       " 3386,\n",
       " 18258,\n",
       " 363,\n",
       " 26520,\n",
       " 9593,\n",
       " 8449,\n",
       " 404,\n",
       " 261,\n",
       " 2569,\n",
       " 38838,\n",
       " 1504,\n",
       " 33298,\n",
       " 287]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05a64c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, 0, 0, -1, -1, 0, -1, 3, -1, -1, 0, 0, 0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cc3bfdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'senjō no valkyria 3, <unk> chronicles ('"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5acedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = tokenizer.encode(\".?,-!\")[1:-1]\n",
    "target_token2id = {t: tokenizer.encode(t)[-2] for t in \".?,-!\"}\n",
    "target_ids = list(target_token2id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba262df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 323, '?': 1102, ',': 366, '-': 341, '!': 1084}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf711ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2target = {\n",
    "#     0: 0,\n",
    "#     -1: -1,\n",
    "# }\n",
    "# for i, ti in enumerate(target_ids):\n",
    "#     id2target[ti] = i+1\n",
    "# target2id = {value: key for key, value in id2target.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c871886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing texts\n",
    "id2target = {\n",
    "    0: 0,\n",
    "    -1: -1,\n",
    "}\n",
    "for i, ti in enumerate(target_ids):\n",
    "    id2target[ti] = i+1\n",
    "target2id = {value: key for key, value in id2target.items()}\n",
    "\n",
    "def create_target(text):\n",
    "    encoded_words, targets = [], []\n",
    "    \n",
    "    words = text.split(' ')\n",
    "\n",
    "    for word in words:\n",
    "        target = 0\n",
    "        for target_token, target_id in target_token2id.items():\n",
    "            if word.endswith(target_token):\n",
    "                target = id2target[target_id]\n",
    "\n",
    "        encoded_word = tokenizer.encode(word, add_special_tokens=False)\n",
    "        if len(encoded_word) == 0:\n",
    "            continue\n",
    "        for w in encoded_word:\n",
    "            encoded_words.append(w)\n",
    "        for _ in range(len(encoded_word)-1):\n",
    "            targets.append(-1)\n",
    "        targets.append(target)\n",
    "        \n",
    "        assert(len(encoded_word)>0)\n",
    "\n",
    "    encoded_words = [tokenizer.cls_token_id or tokenizer.bos_token_id] +\\\n",
    "                    encoded_words +\\\n",
    "                    [tokenizer.sep_token_id or tokenizer.eos_token_id]\n",
    "    targets = [-1] + targets + [-1]\n",
    "    \n",
    "    return encoded_words, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc341c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcfa31e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [PAD]\n",
      "1 .\n",
      "2 ?\n",
      "3 ,\n",
      "4 -\n",
      "5 !\n"
     ]
    }
   ],
   "source": [
    "for k, v in target2id.items():\n",
    "    if k != -1:\n",
    "        print(k, tokenizer.decode(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7495206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-запятая 0-пробел 1-точка 2-вопрос 4-параграф"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6ca8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1422ef7ab34de88498a3366f4bda85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_texts, targets = [], []\n",
    "for text in tqdm(train_text[:500_000]):\n",
    "    enc, tag = create_target(text)\n",
    "    encoded_texts.append(enc)\n",
    "    targets.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896f9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_targets, test_texts, test_targets = encoded_texts[:-3000], targets[:-3000], \\\n",
    "                                                        encoded_texts[-3000:], targets[-3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04d9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_train_words.txt', 'w') as words_file, \\\n",
    "    open('processed_train_targets.txt', 'w') as targets_file:\n",
    "    for words, targets in zip(train_texts, train_targets):\n",
    "        words_file.write(' '.join(map(str, words)) + '\\n')\n",
    "        targets_file.write(' '.join(map(str, targets)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3911775",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_val_words.txt', 'w') as words_file, \\\n",
    "    open('processed_val_targets.txt', 'w') as targets_file:\n",
    "    for words, targets in zip(test_texts, test_targets):\n",
    "        words_file.write(' '.join(map(str, words)) + '\\n')\n",
    "        targets_file.write(' '.join(map(str, targets)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6d1e3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "#creating datasets\n",
    "class BertDataset(Dataset):\n",
    "    def __init__(self, path, path_targets, is_train=False):\n",
    "\n",
    "        self.is_train = is_train\n",
    "        self.encoded_texts = []\n",
    "        self.targets = []\n",
    "        with open(path, 'r') as f:\n",
    "            for text in f.readlines():\n",
    "                self.encoded_texts.extend(list(map(int, text.split())))\n",
    "        with open(path_targets, 'r') as ft:\n",
    "            for text in ft.readlines():\n",
    "                self.targets.extend(list(map(int, text.split())))\n",
    "        \n",
    "        self.encoded_texts = np.array(self.encoded_texts)\n",
    "        self.targets = np.array(self.targets)\n",
    "        idxs = []\n",
    "        \n",
    "        for i, (text, target) in enumerate(zip(self.encoded_texts, self.targets)):\n",
    "            if target >= 1:\n",
    "                idxs.append(i)\n",
    "                self.targets[i - 1] = target\n",
    "\n",
    "        self.encoded_texts = np.delete(self.encoded_texts, idxs)\n",
    "        self.targets = np.delete(self.targets, idxs)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * 2048\n",
    "        start_idx = max(0, start_idx)\n",
    "        end_idx = start_idx + 2048\n",
    "        return torch.LongTensor(self.encoded_texts[start_idx: end_idx]),\\\n",
    "               torch.LongTensor(self.targets[start_idx: end_idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)//2048 - 1\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    texts, targets = zip(*batch)\n",
    "    return torch.stack(texts), torch.stack(targets)\n",
    "\n",
    "def get_datasets():\n",
    "    train_dataset = BertDataset('processed_train_words-2.txt', 'processed_train_targets-2.txt', is_train=True)\n",
    "    valid_dataset = BertDataset('processed_val_words-2.txt', 'processed_val_targets-2.txt')\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "\n",
    "def get_data_loaders(train_dataset, valid_dataset):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, num_workers=0, collate_fn=collate, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=2, collate_fn=collate)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08322244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = nn.Sequential(\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0,2),\n",
    "            nn.Linear(512, 1))\n",
    "        self.linear = nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        binary_output = torch.sigmoid(self.x(x))\n",
    "        x = self.linear(x)\n",
    "        return x, binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a19197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16dfe00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class BertPunctuator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        config = AutoConfig.from_pretrained('microsoft/deberta-v3-base')\n",
    "        config.max_position_embeddings = 2048\n",
    "        self.base = AutoModel.from_pretrained('microsoft/deberta-v3-base', config=config)\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.base(x).last_hidden_state\n",
    "        output, binary_output = self.classifier(embedding)\n",
    "        output = F.log_softmax(output, dim=-1)\n",
    "        return output, binary_output\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        if mode:\n",
    "            self.base.train()\n",
    "            self.classifier.train()\n",
    "        else:\n",
    "            self.base.eval()\n",
    "            self.classifier.eval()\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        self.train(False)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "388edbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "class LinearScheduler(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, max_steps=10000):\n",
    "        self.max_steps = max_steps\n",
    "        self.lr = 0\n",
    "        super().__init__(optimizer, -1)\n",
    "\n",
    "    def get_lr(self):\n",
    "        self.lr = self.base_lrs[-1] * min(1, self._step_count/self.max_steps)\n",
    "        return [base_lr * min(1, self._step_count/self.max_steps)\n",
    "                for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96973fd",
   "metadata": {},
   "source": [
    "вводим-на самом деле\n",
    "\n",
    "0-2\n",
    "\n",
    "2-0\n",
    "\n",
    "4-4\n",
    "\n",
    "\n",
    "5-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff922b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46da7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "train_dataset, valid_dataset = get_datasets()\n",
    "train_loader, valid_loader = get_data_loaders(train_dataset, valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5fb6a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertPunctuator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "95d01661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_weights(targets, output_dim, reduce_empty=True):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=range(-1, 6), y=targets)[1:] # exclude -1\n",
    "    return weights\n",
    "\n",
    "\n",
    "target_weights = torch.Tensor(get_target_weights(train_dataset.targets, 1)).clamp_max(1).to(device)\n",
    "\n",
    "criterion = nn.NLLLoss(weight=target_weights, reduction='none')\n",
    "\n",
    "optimizer_args = [\n",
    "                {'params': model.base.parameters(), 'lr': 3e-5},\n",
    "                {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "            ]\n",
    "optimizer = torch.optim.Adam(optimizer_args)\n",
    "sched = LinearScheduler(optimizer, 500)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b4644b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_state_dict.pt')\n",
    "# torch.save(optimizer.state_dict(), 'optimizer_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a9d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = text.to(device)\n",
    "# emb = model.base(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f3b2082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.11346447467803955, lr: 3e-05:  26%|██▌       | 3665/14162 [3:07:35<9:32:28,  3.27s/it]               IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.14867070317268372, lr: 3e-05:  69%|██████▉   | 9795/14162 [7:28:02<1:13:57,  1.02s/it]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.052787523716688156, lr: 3e-05: 100%|██████████| 14162/14162 [8:42:12<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    torch.save(model.state_dict(), 'model_state_dict_deberta.pt')\n",
    "    torch.save(optimizer.state_dict(), 'optimizer_state_dict_deberta.pt')\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, data in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            text, targets = data\n",
    "            preds, binary_preds = model(text.to(device))\n",
    "\n",
    "            # Mask some \"empty\" targets\n",
    "            mask = ((targets == 0) & (np.random.rand(*targets.shape) < .1)) | (targets > 0)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            # Do not predict output after tokens which are not the end of a word\n",
    "            not_a_word_mask = (targets == -1).to(device)\n",
    "            word_mask = ~not_a_word_mask\n",
    "            targets[not_a_word_mask] = 0\n",
    "\n",
    "            losses = criterion(preds.reshape(-1, 6), targets.to(device).reshape(-1))\n",
    "            losses = losses.reshape(text.size(0), text.size(1))\n",
    "            mask = word_mask * mask\n",
    "            \n",
    "            loss = torch.sum(losses * mask) / torch.sum(mask)\n",
    "            loss.backward()\n",
    "            \n",
    "            pbar.set_description(f\"loss: {loss.item()}, lr: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.5)\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "\n",
    "        # Save model every epoch\n",
    "        torch.save(model.state_dict(), 'model_state_dict_deberta.pt')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer_state_dict_deberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "952f5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                f1_score, roc_auc_score, precision_score, recall_score)\n",
    "\n",
    "def get_classification_report(target, preds):\n",
    "    report = classification_report(target, preds, output_dict=True)\n",
    "    report_print = classification_report(target, preds, digits=3)\n",
    "    return report, report_print\n",
    "\n",
    "\n",
    "def get_eval_metrics(targets, preds):\n",
    "    metrics = {}\n",
    "\n",
    "    preds = np.exp(preds)\n",
    "    preds = preds.reshape(-1, 6)\n",
    "    targets = targets.reshape(-1)\n",
    "    pred_index = preds.argmax(-1)\n",
    "\n",
    "    cls_report, cls_report_print = get_classification_report(targets, pred_index)\n",
    "    print(cls_report_print)\n",
    "    metrics['cls_report'] = cls_report\n",
    "\n",
    "\n",
    "    macro_precision = precision_score(targets, pred_index, average='macro')\n",
    "    metrics['precision'] = macro_precision\n",
    "\n",
    "    macro_recall = recall_score(targets, pred_index, average='macro')\n",
    "    metrics['recall'] = macro_recall\n",
    "\n",
    "    macro_f1_score = f1_score(targets, pred_index, average='macro')\n",
    "    metrics['f_score'] = macro_f1_score\n",
    "\n",
    "    auc_score = roc_auc_score(targets, preds, average='macro', multi_class='ovo')\n",
    "    metrics['auc'] = auc_score\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e257127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:41<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.999     0.921     0.959    251420\n",
      "           1      0.852     0.961     0.903     13253\n",
      "           2      0.424     0.800     0.554        35\n",
      "           3      0.515     0.966     0.671     20072\n",
      "           4      0.871     0.918     0.894       575\n",
      "           5      0.349     0.520     0.417       102\n",
      "\n",
      "    accuracy                          0.926    285457\n",
      "   macro avg      0.668     0.848     0.733    285457\n",
      "weighted avg      0.957     0.926     0.935    285457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valid loop\n",
    "\n",
    "model.eval()\n",
    "valid_loss = 0\n",
    "all_valid_preds = []\n",
    "all_valid_targets = []\n",
    "for data in tqdm(valid_loader):\n",
    "\n",
    "    text, targets = data\n",
    "    with torch.no_grad():\n",
    "        preds, _ = model(text.to(device))\n",
    "\n",
    "    word_mask = targets != -1\n",
    "    preds = preds[word_mask]\n",
    "    targets = targets[word_mask]\n",
    "\n",
    "    loss = criterion(preds.view(-1, 6), targets.to(device).view(-1))\n",
    "    valid_loss += loss.mean().item()\n",
    "    all_valid_preds.append(preds.detach().cpu().numpy())\n",
    "    all_valid_targets.append(targets)\n",
    "\n",
    "\n",
    "valid_loss /= len(valid_loader)\n",
    "all_valid_preds = np.concatenate(all_valid_preds)\n",
    "all_valid_targets = np.concatenate(all_valid_targets)\n",
    "\n",
    "metrics = get_eval_metrics(all_valid_targets, all_valid_preds)\n",
    "metrics[\"loss\"] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01f46210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, -1: -1, 1: 323, 2: 1102, 3: 366, 4: 341, 5: 1084}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a44824af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([341])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "22c70099",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict_deberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9dd838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertPunctuator()\n",
    "model.load_state_dict(torch.load('model_gdown.pt', map_location='cpu'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8177f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_symb(symb):\n",
    "    if symb == -1:\n",
    "        return ''\n",
    "    if symb == 0:\n",
    "        return ' '\n",
    "    return tokenizer.decode(target2id[symb]) + ' '\n",
    "\n",
    "def predict_model(text):\n",
    "    encoded_input, targets = create_target(text)\n",
    "    encoded_input_tens = torch.LongTensor([encoded_input])\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(encoded_input_tens)\n",
    "        \n",
    "    output = output[0]\n",
    "    output_idx = torch.argmax(output, dim=-1)\n",
    "    array = []\n",
    "    for token, symb, target in zip(encoded_input[1:-1], output_idx.numpy().tolist()[1:-1], targets[1:-1]):\n",
    "        if target == -1:\n",
    "            vale = tokenizer.decode(token)\n",
    "        elif target == 0:\n",
    "            vale = tokenizer.decode(token) + decode_symb(symb)\n",
    "        else:\n",
    "            vale = tokenizer.decode(token) + ' '#  + tokenizer.decode(target2id[target]) + ' '\n",
    "        array.append(vale)\n",
    "    return ''.join(array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c8204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, how are you? \n",
      "if i could save time in a bottle, first thing that i would like to do, is to save every day. \n",
      "what does society mean? in? my, opinion, it is we, people, who rule over it. \n",
      "i like apples and tomatos. \n",
      "will? i get a possitive mark for this task? \n"
     ]
    }
   ],
   "source": [
    "print(predict_model('hello how are you'))\n",
    "print(predict_model('if i could save time in a bottle first thing that i would like to do is to save every day'))\n",
    "print(predict_model('what does society mean in my opinion it is we people who rule over it'))\n",
    "print(predict_model('i like apples and tomatos'))\n",
    "print(predict_model('will i get a possitive mark for this task'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd691b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how should i tell varya, that i love her? \n"
     ]
    }
   ],
   "source": [
    "print(predict_model('how should i tell varya that i love her'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73ccf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='I hate him because of his stubbornness How do I handle this'\n",
    "prepared_text=clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ab69c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hate him because of his stubbornness how do i handle this'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1498d830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i hate him, because of his stubbornness. how do i handle this? '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6eefa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_text = 'a book display with works on critical race theory critical race theory (crt) is a cross disciplinary intellectual and social movement of civil rights scholars and activists who seek to examine the intersection of race society and law in the united states and to challenge mainstream american liberal approaches to racial justice the word critical in its name is an academic term that refers to critical thinking critical theory and scholarly criticism rather than criticizing or blaming people crt is also used in sociology to explain social political and legal structures and power distribution through the lens of race for example the crt conceptual framework is one way to study racial bias in laws and institutions such as the how and why of incarceration rates and how sentencing differs among racial groups in the united states it first arose in the 1970s like other critical schools of thought such as critical legal studies which examines how legal rules protect the status quo a key crt concept is intersectionality the way in which different forms of inequality and identity are affected by interconnections of race class gender and disability scholars of crt view race as a social construct with no biological basis one tenet of crt is that racism and disparate racial outcomes are the result of complex changing and often subtle social and institutional dynamics rather than explicit and intentional prejudices of individuals crt scholars argue that the social and legal construction of race advances the interests of white people at the expense of people of color and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where formally color,blind laws continue to have racially discriminatory outcomes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efb82240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book display with works on critical race theory critical race theory (crt) is a cross disciplinary intellectual and social movement of civil rights scholars and activists who seek to examine the intersection of race society and law in the united states and to challenge mainstream american liberal approaches to racial justice the word critical in its name is an academic term that refers to critical thinking critical theory and scholarly criticism rather than criticizing or blaming people crt is also used in sociology to explain social political and legal structures and power distribution through the lens of race for example the crt conceptual framework is one way to study racial bias in laws and institutions such as the how and why of incarceration rates and how sentencing differs among racial groups in the united states it first arose in the 1970s like other critical schools of thought such as critical legal studies which examines how legal rules protect the status quo a key crt concept is intersectionality the way in which different forms of inequality and identity are affected by interconnections of race class gender and disability scholars of crt view race as a social construct with no biological basis one tenet of crt is that racism and disparate racial outcomes are the result of complex changing and often subtle social and institutional dynamics rather than explicit and intentional prejudices of individuals crt scholars argue that the social and legal construction of race advances the interests of white people at the expense of people of color and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where formally color,blind laws continue to have racially discriminatory outcomes'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1285f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book, display, with works on critical race theory, critical race theory (crt), is a cross, disciplinary, intellectual, and social movement of civil, rights scholars and activists, who seek to examine the intersection of race, society, and law in the united states, and to challenge mainstream american, liberal approaches to racial justice. the word critical in its name, is an academic term that refers to critical, thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology, to explain social, political, and legal structures, and power distribution, through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how and why of incarceration rates, and how sentencing differs among racial groups in the united states. it first arose in the 1970s, like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status quo. a key crt concept is intersectionality, the way in which different forms of inequality and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct, with no biological basis. one tenet of crt is that racism, and disparate racial outcomes are the result of complex, changing, and often subtle, social and institutional dynamics, rather than explicit and intentional prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people, at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where, formally, color,blind laws continue to have racially discriminatory outcomes. '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3f3d69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book, display, with works on critical race theory, critical race theory (crt), is a cross, disciplinary, intellectual, and social movement of civil, rights scholars and activists, who seek to examine the intersection of race, society, and law in the united states, and to challenge mainstream american, liberal approaches to racial justice. the word critical in its name, is an academic term that refers to critical, thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology, to explain social, political, and legal structures, and power distribution, through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how and why of incarceration rates, and how sentencing differs among racial groups in the united states. it first arose in the 1970s, like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status quo. a key crt concept is intersectionality, the way in which different forms of inequality and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct, with no biological basis. one tenet of crt is that racism, and disparate racial outcomes are the result of complex, changing, and often subtle, social and institutional dynamics, rather than explicit and intentional prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people, at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where, formally, color,blind laws continue to have racially discriminatory outcomes. '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cff2e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book display with works on critical race theory critical race theory (crt) is a cross,disciplinary intellectual and social movement of civil,rights scholars and activists who seek to examine the intersection of race, society, and law in the united states and to challenge mainstream american liberal approaches to racial justice. the word critical in its name is an academic term that refers to critical thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology to explain social, political, and legal structures and power distribution through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how and why of incarceration rates and how sentencing differs among racial groups in the united states. it first arose in the 1970s, like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status quo. a key crt concept is intersectionality—the way in which different forms of inequality and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct with no biological basis. one tenet of crt is that racism and disparate racial outcomes are the result of complex, changing, and often subtle social and institutional dynamics, rather than explicit and intentional prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where formally color,blind laws continue to have racially discriminatory outcomes.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0af85492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a book, display, with works on critical race theory, critical race theory (crt), is a cross,disciplinary, intellectual, and social movement of civil,rights, scholars and activists, who seek to examine the intersection of race, society, and law in the united states, and to challenge mainstream american, liberal approaches to racial justice. the word critical in its name, is an academic term that refers to critical thinking, critical theory, and scholarly criticism, rather than criticizing or blaming people. crt is also used in sociology, to explain social, political, and legal structures, and power distribution, through the lens of race. for example, the crt conceptual framework is one way to study racial bias in laws and institutions, such as the how and why of incarceration rates, and how sentencing differs among racial groups in the united states. it first arose in the 1970s, like other critical schools of thought, such as critical legal studies, which examines how legal rules protect the status quo. a key crt concept is intersectionality—the way in which different forms of inequality and identity are affected by interconnections of race, class, gender, and disability. scholars of crt view race as a social construct, with no biological basis. one tenet of crt is that racism, and disparate racial outcomes are the result of complex, changing, and often subtle, social and institutional dynamics, rather than explicit and intentional prejudices of individuals. crt scholars argue that the social and legal construction of race advances the interests of white people, at the expense of people of color, and that the liberal notion of u.s. law as \"neutral\" plays a significant role in maintaining a racially unjust social order, where, formally, color,blind laws continue to have racially, discriminatory outcomes. '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bc74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553d253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf640a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 197/197 [00:08<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.998     0.920     0.957    266444\n",
      "           1      0.770     0.969     0.858       614\n",
      "           2      0.280     0.857     0.423        35\n",
      "           3      0.483     0.972     0.646     20210\n",
      "\n",
      "    accuracy                          0.924    287303\n",
      "   macro avg      0.633     0.930     0.721    287303\n",
      "weighted avg      0.961     0.924     0.935    287303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valid loop\n",
    "\n",
    "model.eval()\n",
    "valid_loss = 0\n",
    "all_valid_preds = []\n",
    "all_valid_targets = []\n",
    "for data in tqdm(valid_loader):\n",
    "\n",
    "    text, targets = data\n",
    "    with torch.no_grad():\n",
    "        preds, _ = model(text.to(device))\n",
    "\n",
    "    word_mask = targets != -1\n",
    "    preds = preds[word_mask]\n",
    "    targets = targets[word_mask]\n",
    "\n",
    "    loss = criterion(preds.view(-1, 4), targets.to(device).view(-1))\n",
    "    valid_loss += loss.mean().item()\n",
    "    all_valid_preds.append(preds.detach().cpu().numpy())\n",
    "    all_valid_targets.append(targets)\n",
    "\n",
    "\n",
    "valid_loss /= len(valid_loader)\n",
    "all_valid_preds = np.concatenate(all_valid_preds)\n",
    "all_valid_targets = np.concatenate(all_valid_targets)\n",
    "\n",
    "metrics = get_eval_metrics(all_valid_targets, all_valid_preds)\n",
    "metrics[\"loss\"] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fac09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ed95035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cls_report': {'0': {'precision': 0.9977659405634387,\n",
       "   'recall': 0.9202383990632178,\n",
       "   'f1-score': 0.9574353016976288,\n",
       "   'support': 266444},\n",
       "  '1': {'precision': 0.7697283311772316,\n",
       "   'recall': 0.9690553745928339,\n",
       "   'f1-score': 0.8579668348954579,\n",
       "   'support': 614},\n",
       "  '2': {'precision': 0.2803738317757009,\n",
       "   'recall': 0.8571428571428571,\n",
       "   'f1-score': 0.4225352112676056,\n",
       "   'support': 35},\n",
       "  '3': {'precision': 0.4831129246349737,\n",
       "   'recall': 0.9724888668975754,\n",
       "   'f1-score': 0.6455363594560862,\n",
       "   'support': 20210},\n",
       "  'accuracy': 0.9240105393956902,\n",
       "  'macro avg': {'precision': 0.6327452570378362,\n",
       "   'recall': 0.929731374424121,\n",
       "   'f1-score': 0.7208684268291946,\n",
       "   'support': 287303},\n",
       "  'weighted avg': {'precision': 0.960988526934326,\n",
       "   'recall': 0.9240105393956902,\n",
       "   'f1-score': 0.9352173897214812,\n",
       "   'support': 287303}},\n",
       " 'precision': 0.6327452570378362,\n",
       " 'recall': 0.929731374424121,\n",
       " 'f_score': 0.7208684268291946,\n",
       " 'auc': 0.9930891773177869,\n",
       " 'loss': 0.06951378435274672}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c9bb25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64499571"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5262ee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363140"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad044afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
